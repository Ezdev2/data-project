{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations nécessaires pour Airflow\n",
    "from datetime import timedelta, datetime\n",
    "from airflow.models import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "# Définition des paramètres par défaut pour les tâches de la DAG\n",
    "default_args = {\n",
    "    'owner': 'eco_educ',  # Propriétaire de la DAG\n",
    "    'start_date': datetime(2023, 8, 3),  # Date de début de la DAG\n",
    "    'retries': 1,  # Nombre de tentatives en cas d'échec\n",
    "    'retry_delay': timedelta(minutes=1)  # Délai entre les tentatives\n",
    "}\n",
    "\n",
    "# Création de la DAG\n",
    "test_with_dags = DAG('test_with_dags', \n",
    "                     default_args=default_args, \n",
    "                     description='ETL jobs for Data', \n",
    "                     schedule_interval='@daily',  # Fréquence d'exécution quotidienne\n",
    "                     catchup=False,  # Ignorer les exécutions manquées\n",
    "                     tags=['example', 'testdags']  # Tags pour la DAG\n",
    "                    )\n",
    "\n",
    "# Fonction pour extraire les données\n",
    "def extract_jobs():\n",
    "    # Lien du fichier à extraire\n",
    "    apps = extract_datas('')  # Appel à une fonction \"extract_datas\"\n",
    "    return apps\n",
    "\n",
    "# Appel de la fonction d'extraction\n",
    "gapps, greviews = extract_jobs()\n",
    "\n",
    "# Fonction pour effectuer les transformations sur les données\n",
    "def transform_jobs(df1):\n",
    "    # Fonction pour effectuer les transformations nécessaires\n",
    "    # prenant en paramètre le DataFrame df1\n",
    "    return extract_to_csv(df1)  # Appel à une fonction \"extract_to_csv\"\n",
    "\n",
    "# Fonction pour charger les données transformées\n",
    "def load_jobs():\n",
    "    # Lien pour l'upload des données\n",
    "    return uploadToS3('subject', '')  # Appel à une fonction \"uploadToS3\"\n",
    "\n",
    "# Création des opérateurs de tâches\n",
    "start_task = DummyOperator(task_id='start_task', dag=test_with_dags)\n",
    "extract_dags = PythonOperator(task_id='extract_dags', python_callable=extract_jobs, dag=test_with_dags)\n",
    "transform_dags = PythonOperator(task_id='transform_dags', python_callable=transform_jobs, op_args=gapps, dag=test_with_dags)\n",
    "load_dags = PythonOperator(task_id='load_dags', python_callable=load_jobs, dag=test_with_dags)\n",
    "end_task = DummyOperator(task_id='end_task', dag=test_with_dags)\n",
    "\n",
    "# Définition des dépendances entre les tâches\n",
    "start_task >> extract_dags >> transform_dags >> load_dags >> end_task\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
